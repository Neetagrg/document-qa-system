[
    {
        "page": 1,
        "text": "AI in Health CUS635 03/10/2025\nAuthors: Neeta Kumari., Bir Bhadur Gharti\nInstitution: St. John's University, Queens, NY 08544, USA\nObjective\nThis project involves retrieving news articles related to \"AI in Health\" using a public API,\ncleaning the data, and then storing it in an AWS S3 bucket for later use. We used\nNewsAPI.org to fetch articles based on specific search parameters and filters. After\ncleaning the data to ensure consistency and usability, we uploaded it to an S3 bucket\nunder the folder structure that makes sense for our project.\nKey Steps in the Project\n1. API Setup and Fetching Data:\na. We interacted with the NewsAPI.org to fetch articles about \"AI in Health\"\nunder the technology section. The API allows us to filter articles based on\nvarious parameters, such as the date, category, and page size.\nb. We used pagination to retrieve a maximum of 1000 articles in total, by\nmaking multiple requests to the API.\n2. Cleaning the Data:\na. The retrieved data, consisting of news articles, was cleaned to remove\nduplicates and any incomplete or missing entries.\nb. We processed the data to extract key details such as the article's title,\ndescription, source, and the full content, ensuring that we could store and\nanalyze it efficiently.\n3. Saving the Cleaned Data:\na. After cleaning the data, we saved it in a CSV format. This format was\nchosen for easy reading, manipulation, and analysis in tools like Excel or\npandas (a Python data analysis library).\nb. We could also save the data in JSON format, but CSV was preferred due to\nits simplicity and wide usage in data processing.\n4. Uploading Data to AWS S3:\na. Once the data was saved in a CSV file, it was uploaded to an AWS S3\nbucket (designated for the project). The S3 service was chosen because it\nprovides a scalable and reliable storage solution, which is perfect for\nhandling large amounts of data.\nb. The uploaded data was organized under a folder structure based on the\nteam name and the category of the articles. For example, all data related to\n\"AI in Health\" was stored under the folder TEAM_6/AI_in_health/."
    },
    {
        "page": 2,
        "text": "S3 Folder Structure\nThe folder structure on the S3 bucket was organized as follows:\nmarkdown\nCopyEdit\ncus635-spring2025/\nTEAM_6/\nAI_in_health/\nteam_6_ai_in_health.csv\nThis organization ensures that data is grouped logically by team and category, making it\neasy for both storage and retrieval in the future.\nChallenges and Solutions\n• Challenge with API Pagination:\no The API limited the number of articles that could be fetched in one request,\nso we had to handle pagination to gather all articles. We set the page-size\nparameter to 200 articles per page and iterated through multiple pages to\nget up to 1000 articles.\no Solution: We implemented a loop to fetch data across 5 pages, ensuring\nthat we collected a substantial amount of articles for our analysis.\n• Data Cleaning:\no Some of the articles contained missing information, duplicates, or\nunnecessary HTML tags. We had to clean the data thoroughly to ensure\nconsistency.\no Solution: We created scripts that removed any articles with missing titles or\ndescriptions, deduplicated entries, and formatted the text to make it usable\nfor storage.\n• Uploading Data to S3:\no Initially, there was uncertainty around organizing the data in the S3 bucket\nto ensure it was structured in a way that matched the project requirements.\no Solution: We organized the data into folders named after the team and\ncategory (e.g., TEAM_6/AI_in_health/). This approach made it easy to locate\nthe correct files later on."
    },
    {
        "page": 3,
        "text": "Technical Details\n• API Used: NewsAPI.org\n• Programming Language: Python\n• Libraries Used:\no requests: For interacting with the NewsAPI to fetch articles.\no pandas: For organizing the data and saving it into a CSV file.\no boto3: For interacting with AWS S3 to upload the cleaned data.\n• Storage: AWS S3 Bucket (provided by the professor)\n• Data Format: CSV (for easy data manipulation and storage)\nFuture Improvements\n• Increase the Number of Articles: We could fetch more than 1000 articles by\nmodifying the API request or by handling rate limits more effectively.\n• Data Analysis: After storing the data, we could perform an analysis on the articles,\nsuch as identifying trends in AI in health news, summarizing article topics, or\nsentiment analysis on the content.\n• User Interface (UI): We could build a simple UI to allow users to query the data,\nview articles, and download them.\nConclusion\nThis project successfully demonstrates how to interact with public APIs, retrieve large-\nscale textual data, clean the data, and store it in a cloud-based solution like AWS S3. By\nbreaking down the steps and tackling challenges, we were able to complete the task\nefficiently and ensure that the data is well-organized and accessible for future use."
    }
]